{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b903a-5a1b-47c8-afce-7e0598bfd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Credit Card Fraud Detection\",\n",
    "    page_icon=\"üîê\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Custom CSS\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        font-size: 3rem;\n",
    "        color: #1f77b4;\n",
    "        text-align: center;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    .metric-card {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        margin: 0.5rem 0;\n",
    "    }\n",
    "    .fraud-alert {\n",
    "        background-color: #ffebee;\n",
    "        color: #c62828;\n",
    "        padding: 1rem;\n",
    "        border-radius: 5px;\n",
    "        border-left: 4px solid #c62828;\n",
    "    }\n",
    "    .safe-alert {\n",
    "        background-color: #e8f5e8;\n",
    "        color: #2e7d32;\n",
    "        padding: 1rem;\n",
    "        border-radius: 5px;\n",
    "        border-left: 4px solid #2e7d32;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Generate sample data\n",
    "@st.cache_data\n",
    "def generate_sample_data(n_samples=5000):\n",
    "    \"\"\"Generate realistic credit card transaction data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate normal transactions\n",
    "    normal_transactions = int(n_samples * 0.98)  # 98% normal\n",
    "    fraud_transactions = n_samples - normal_transactions  # 2% fraud\n",
    "    \n",
    "    # Normal transaction features\n",
    "    normal_data = {\n",
    "        'amount': np.random.lognormal(3, 1, normal_transactions),\n",
    "        'time_since_last_transaction': np.random.exponential(2, normal_transactions),\n",
    "        'merchant_category': np.random.choice(['grocery', 'gas', 'restaurant', 'retail', 'online'], normal_transactions),\n",
    "        'location_risk_score': np.random.beta(2, 8, normal_transactions),\n",
    "        'time_of_day': np.random.normal(12, 6, normal_transactions) % 24,\n",
    "        'day_of_week': np.random.choice(range(7), normal_transactions),\n",
    "        'is_weekend': np.random.choice([0, 1], normal_transactions, p=[0.7, 0.3]),\n",
    "        'customer_age': np.random.normal(45, 15, normal_transactions),\n",
    "        'account_age_days': np.random.normal(1000, 500, normal_transactions),\n",
    "        'previous_failed_attempts': np.random.poisson(0.1, normal_transactions),\n",
    "        'is_fraud': np.zeros(normal_transactions)\n",
    "    }\n",
    "    \n",
    "    # Fraudulent transaction features (different patterns)\n",
    "    fraud_data = {\n",
    "        'amount': np.concatenate([\n",
    "            np.random.lognormal(2, 0.5, fraud_transactions//2),  # Small amounts\n",
    "            np.random.lognormal(6, 1, fraud_transactions//2)     # Large amounts\n",
    "        ]),\n",
    "        'time_since_last_transaction': np.random.exponential(0.5, fraud_transactions),\n",
    "        'merchant_category': np.random.choice(['online', 'retail', 'gas'], fraud_transactions),\n",
    "        'location_risk_score': np.random.beta(8, 2, fraud_transactions),\n",
    "        'time_of_day': np.random.choice([2, 3, 4, 22, 23], fraud_transactions),\n",
    "        'day_of_week': np.random.choice(range(7), fraud_transactions),\n",
    "        'is_weekend': np.random.choice([0, 1], fraud_transactions, p=[0.4, 0.6]),\n",
    "        'customer_age': np.random.normal(35, 20, fraud_transactions),\n",
    "        'account_age_days': np.random.normal(200, 300, fraud_transactions),\n",
    "        'previous_failed_attempts': np.random.poisson(2, fraud_transactions),\n",
    "        'is_fraud': np.ones(fraud_transactions)\n",
    "    }\n",
    "    \n",
    "    # Combine data\n",
    "    data = {}\n",
    "    for key in normal_data.keys():\n",
    "        data[key] = np.concatenate([normal_data[key], fraud_data[key]])\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add some derived features\n",
    "    df['amount_zscore'] = (df['amount'] - df['amount'].mean()) / df['amount'].std()\n",
    "    df['velocity_risk'] = 1 / (df['time_since_last_transaction'] + 0.1)\n",
    "    df['late_night_transaction'] = ((df['time_of_day'] >= 22) | (df['time_of_day'] <= 6)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and prepare data\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = generate_sample_data()\n",
    "    return df\n",
    "\n",
    "# Train model\n",
    "@st.cache_resource\n",
    "def train_model(df):\n",
    "    \"\"\"Train fraud detection model\"\"\"\n",
    "    feature_columns = ['amount', 'time_since_last_transaction', 'location_risk_score', \n",
    "                      'time_of_day', 'day_of_week', 'is_weekend', 'customer_age', \n",
    "                      'account_age_days', 'previous_failed_attempts', 'amount_zscore', \n",
    "                      'velocity_risk', 'late_night_transaction']\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df['is_fraud']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    return model, scaler, X_test, y_test, y_pred, y_pred_proba, feature_columns\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.markdown('<h1 class=\"main-header\">üîê Credit Card Fraud Detection System</h1>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Load data and train model\n",
    "    df = load_data()\n",
    "    model, scaler, X_test, y_test, y_pred, y_pred_proba, feature_columns = train_model(df)\n",
    "    \n",
    "    # Sidebar\n",
    "    st.sidebar.header(\"Navigation\")\n",
    "    page = st.sidebar.selectbox(\"Choose a page\", [\"Dashboard\", \"Single Transaction Check\", \"Batch Analysis\", \"Model Performance\"])\n",
    "    \n",
    "    if page == \"Dashboard\":\n",
    "        dashboard_page(df, model, scaler, feature_columns)\n",
    "    elif page == \"Single Transaction Check\":\n",
    "        single_transaction_page(model, scaler, feature_columns)\n",
    "    elif page == \"Batch Analysis\":\n",
    "        batch_analysis_page(df, model, scaler, feature_columns)\n",
    "    elif page == \"Model Performance\":\n",
    "        model_performance_page(X_test, y_test, y_pred, y_pred_proba, model, feature_columns)\n",
    "\n",
    "def dashboard_page(df, model, scaler, feature_columns):\n",
    "    \"\"\"Main dashboard with overview statistics\"\"\"\n",
    "    st.header(\"üìä Fraud Detection Dashboard\")\n",
    "    \n",
    "    # Key metrics\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\"Total Transactions\", f\"{len(df):,}\")\n",
    "    \n",
    "    with col2:\n",
    "        fraud_count = df['is_fraud'].sum()\n",
    "        fraud_rate = (fraud_count / len(df)) * 100\n",
    "        st.metric(\"Fraud Transactions\", f\"{fraud_count:,}\", f\"{fraud_rate:.2f}%\")\n",
    "    \n",
    "    with col3:\n",
    "        avg_amount = df['amount'].mean()\n",
    "        st.metric(\"Avg Transaction Amount\", f\"${avg_amount:.2f}\")\n",
    "    \n",
    "    with col4:\n",
    "        fraud_amount = df[df['is_fraud'] == 1]['amount'].sum()\n",
    "        st.metric(\"Total Fraud Amount\", f\"${fraud_amount:,.2f}\")\n",
    "    \n",
    "    # Charts\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Transaction Amount Distribution\")\n",
    "        fig = px.histogram(df, x='amount', color='is_fraud', \n",
    "                          title='Transaction Amount Distribution by Fraud Status',\n",
    "                          labels={'is_fraud': 'Fraud Status'})\n",
    "        fig.update_layout(xaxis_title=\"Amount ($)\", yaxis_title=\"Count\")\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Fraud by Time of Day\")\n",
    "        hourly_fraud = df.groupby('time_of_day')['is_fraud'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "        fig = px.bar(hourly_fraud, x='time_of_day', y='mean',\n",
    "                     title='Fraud Rate by Hour of Day',\n",
    "                     labels={'mean': 'Fraud Rate', 'time_of_day': 'Hour'})\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    # Risk factors\n",
    "    st.subheader(\"üéØ Key Risk Factors\")\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Merchant Category Risk\")\n",
    "        merchant_risk = df.groupby('merchant_category')['is_fraud'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "        merchant_risk.columns = ['merchant_category', 'fraud_count', 'total_transactions', 'fraud_rate']\n",
    "        st.dataframe(merchant_risk.sort_values('fraud_rate', ascending=False))\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Location Risk Distribution\")\n",
    "        fig = px.box(df, x='is_fraud', y='location_risk_score',\n",
    "                     title='Location Risk Score by Fraud Status')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "def single_transaction_page(model, scaler, feature_columns):\n",
    "    \"\"\"Page for checking individual transactions\"\"\"\n",
    "    st.header(\"üîç Single Transaction Fraud Check\")\n",
    "    \n",
    "    st.write(\"Enter transaction details to check for fraud probability:\")\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        amount = st.number_input(\"Transaction Amount ($)\", min_value=0.01, value=100.0, step=0.01)\n",
    "        time_since_last = st.number_input(\"Hours Since Last Transaction\", min_value=0.0, value=2.0, step=0.1)\n",
    "        location_risk = st.slider(\"Location Risk Score\", 0.0, 1.0, 0.2, 0.01)\n",
    "        time_of_day = st.slider(\"Time of Day (24h)\", 0, 23, 14)\n",
    "        day_of_week = st.selectbox(\"Day of Week\", [0, 1, 2, 3, 4, 5, 6], format_func=lambda x: ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'][x])\n",
    "        is_weekend = st.checkbox(\"Is Weekend\")\n",
    "    \n",
    "    with col2:\n",
    "        customer_age = st.number_input(\"Customer Age\", min_value=18, max_value=100, value=35)\n",
    "        account_age_days = st.number_input(\"Account Age (Days)\", min_value=0, value=365)\n",
    "        previous_failed = st.number_input(\"Previous Failed Attempts\", min_value=0, value=0)\n",
    "        merchant_category = st.selectbox(\"Merchant Category\", ['grocery', 'gas', 'restaurant', 'retail', 'online'])\n",
    "    \n",
    "    if st.button(\"Check Fraud Risk\", type=\"primary\"):\n",
    "        # Prepare input data\n",
    "        input_data = pd.DataFrame({\n",
    "            'amount': [amount],\n",
    "            'time_since_last_transaction': [time_since_last],\n",
    "            'location_risk_score': [location_risk],\n",
    "            'time_of_day': [time_of_day],\n",
    "            'day_of_week': [day_of_week],\n",
    "            'is_weekend': [1 if is_weekend else 0],\n",
    "            'customer_age': [customer_age],\n",
    "            'account_age_days': [account_age_days],\n",
    "            'previous_failed_attempts': [previous_failed],\n",
    "            'amount_zscore': [(amount - 150) / 200],  # Approximate normalization\n",
    "            'velocity_risk': [1 / (time_since_last + 0.1)],\n",
    "            'late_night_transaction': [1 if (time_of_day >= 22 or time_of_day <= 6) else 0]\n",
    "        })\n",
    "        \n",
    "        # Make prediction\n",
    "        input_scaled = scaler.transform(input_data[feature_columns])\n",
    "        fraud_probability = model.predict_proba(input_scaled)[0][1]\n",
    "        is_fraud_pred = model.predict(input_scaled)[0]\n",
    "        \n",
    "        # Display results\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"Fraud Risk Assessment\")\n",
    "            if fraud_probability > 0.5:\n",
    "                st.markdown(f'<div class=\"fraud-alert\">‚ö†Ô∏è HIGH RISK: {fraud_probability:.1%} fraud probability</div>', unsafe_allow_html=True)\n",
    "            else:\n",
    "                st.markdown(f'<div class=\"safe-alert\">‚úÖ LOW RISK: {fraud_probability:.1%} fraud probability</div>', unsafe_allow_html=True)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"Risk Factors\")\n",
    "            risk_factors = []\n",
    "            if location_risk > 0.7:\n",
    "                risk_factors.append(\"High-risk location\")\n",
    "            if time_of_day >= 22 or time_of_day <= 6:\n",
    "                risk_factors.append(\"Late night transaction\")\n",
    "            if time_since_last < 0.5:\n",
    "                risk_factors.append(\"High transaction velocity\")\n",
    "            if previous_failed > 0:\n",
    "                risk_factors.append(\"Previous failed attempts\")\n",
    "            if amount > 1000:\n",
    "                risk_factors.append(\"Large transaction amount\")\n",
    "            \n",
    "            if risk_factors:\n",
    "                for factor in risk_factors:\n",
    "                    st.write(f\"‚Ä¢ {factor}\")\n",
    "            else:\n",
    "                st.write(\"No significant risk factors detected\")\n",
    "\n",
    "def batch_analysis_page(df, model, scaler, feature_columns):\n",
    "    \"\"\"Page for analyzing batches of transactions\"\"\"\n",
    "    st.header(\"üìã Batch Transaction Analysis\")\n",
    "    \n",
    "    st.write(\"Analyze recent transactions for fraud patterns:\")\n",
    "    \n",
    "    # Sample recent transactions\n",
    "    sample_size = st.slider(\"Number of transactions to analyze\", 50, 500, 100)\n",
    "    sample_df = df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Make predictions for the sample\n",
    "    X_sample = sample_df[feature_columns]\n",
    "    X_sample_scaled = scaler.transform(X_sample)\n",
    "    fraud_probabilities = model.predict_proba(X_sample_scaled)[:, 1]\n",
    "    fraud_predictions = model.predict(X_sample_scaled)\n",
    "    \n",
    "    # Add predictions to dataframe\n",
    "    sample_df = sample_df.copy()\n",
    "    sample_df['fraud_probability'] = fraud_probabilities\n",
    "    sample_df['predicted_fraud'] = fraud_predictions\n",
    "    \n",
    "    # Summary statistics\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    \n",
    "    with col1:\n",
    "        actual_fraud = sample_df['is_fraud'].sum()\n",
    "        st.metric(\"Actual Fraud Cases\", actual_fraud)\n",
    "    \n",
    "    with col2:\n",
    "        predicted_fraud = sample_df['predicted_fraud'].sum()\n",
    "        st.metric(\"Predicted Fraud Cases\", predicted_fraud)\n",
    "    \n",
    "    with col3:\n",
    "        high_risk = (sample_df['fraud_probability'] > 0.3).sum()\n",
    "        st.metric(\"High Risk Transactions\", high_risk)\n",
    "    \n",
    "    # Show high-risk transactions\n",
    "    st.subheader(\"üö® High-Risk Transactions\")\n",
    "    high_risk_df = sample_df[sample_df['fraud_probability'] > 0.3].sort_values('fraud_probability', ascending=False)\n",
    "    \n",
    "    if not high_risk_df.empty:\n",
    "        display_cols = ['amount', 'merchant_category', 'location_risk_score', 'time_of_day', \n",
    "                       'fraud_probability', 'is_fraud', 'predicted_fraud']\n",
    "        st.dataframe(high_risk_df[display_cols].head(20))\n",
    "    else:\n",
    "        st.write(\"No high-risk transactions detected in this sample.\")\n",
    "    \n",
    "    # Visualizations\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Fraud Probability Distribution\")\n",
    "        fig = px.histogram(sample_df, x='fraud_probability', \n",
    "                          title='Distribution of Fraud Probabilities')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Risk vs Amount\")\n",
    "        fig = px.scatter(sample_df, x='amount', y='fraud_probability',\n",
    "                        color='is_fraud', title='Fraud Risk vs Transaction Amount')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "def model_performance_page(X_test, y_test, y_pred, y_pred_proba, model, feature_columns):\n",
    "    \"\"\"Page showing model performance metrics\"\"\"\n",
    "    st.header(\"üìà Model Performance Analysis\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    \n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    \n",
    "    with col1:\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        st.metric(\"Accuracy\", f\"{accuracy:.3f}\")\n",
    "    \n",
    "    with col2:\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        st.metric(\"Precision\", f\"{precision:.3f}\")\n",
    "    \n",
    "    with col3:\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        st.metric(\"Recall\", f\"{recall:.3f}\")\n",
    "    \n",
    "    with col4:\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        st.metric(\"F1 Score\", f\"{f1:.3f}\")\n",
    "    \n",
    "    # ROC Curve\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"ROC Curve\")\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=f'ROC Curve (AUC = {auc_score:.3f})'))\n",
    "        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random'))\n",
    "        fig.update_layout(title='ROC Curve', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Confusion Matrix\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        fig = px.imshow(cm, text_auto=True, aspect=\"auto\",\n",
    "                       labels=dict(x=\"Predicted\", y=\"Actual\"),\n",
    "                       title=\"Confusion Matrix\")\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    # Feature importance\n",
    "    st.subheader(\"Feature Importance\")\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    fig = px.bar(importance_df, x='importance', y='feature', orientation='h',\n",
    "                 title='Feature Importance in Fraud Detection')\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    # Classification report\n",
    "    st.subheader(\"Detailed Classification Report\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    st.dataframe(report_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
